
# FURIA Chat

## Sobre o Projeto

**FURIA Chat** é uma aplicação web desenvolvida em **React** e **Node.js (Express)** que permite aos usuários fazer perguntas e obter informações sobre a FURIA Esports. A aplicação utiliza a **API do ChatGPT (GPT-3.5-turbo)** via back-end para fornecer respostas precisas e contextualizadas sobre o time, seus jogadores, conquistas e histórico.

---

## Funcionalidades

- **Interface de Chat Intuitiva**: Interface simples para interação com o chatbot
- **Filtro de Perguntas**: Garante que apenas perguntas relacionadas à FURIA sejam processadas
- **Mensagens Rápidas**: Sugestões pré-definidas para facilitar o uso
- **Integração com ChatGPT via Backend**: As requisições passam por um servidor Express que faz a chamada à API da OpenAI
- **Links Externos**: Acesso ao site oficial da FURIA e redes sociais
- **Segurança Aprimorada**: A chave da OpenAI é mantida no back-end, protegendo contra exposição

---

## Tecnologias Utilizadas

### Front-end:
- React.js 19.1.0
- Axios
- CSS

### Back-end:
- Node.js + Express
- dotenv
- CORS
- OpenAI SDK

---

## Pré-requisitos para a criação

- Node.js (versão recomendada: 16.x ou superior)
- npm ou yarn
- Conta no Render para hospedagem do back-end
- Chave de API da OpenAI

---
## Para acessar o site: https://teste-furia1.vercel.app/


O Site esta separado em dois repositorios, um para o back-end(https://github.com/LedroPucas/furiabackend) e outro para o front-end (https://github.com/LedroPucas/TesteFuria1), pois, ao criar subi o backend no Render, para ficar hospedado de forma confiavel
para que a Key do GPT, não seja vazada, e podendo assim conectar ao front-end.

Já o Front-end, onde se encontra neste repositório, temos a aplicação React, com todas as suas funcionalidades, e a integração da API do gpt, com os a Key Hospedada no 
Render, fazendo assim o chamado, e ultilizando da API, da melhor forma e setando parametros precisos, para o Usúario poder tirar suas duvidas sobre a Furia no geral.

Logo abaixo, explico o processo de criação do Site...

---

## Configuração do Ambiente

### 1. Clone o repositório:
```bash
git clone <url-do-repositorio>
cd furiachat
```

---

### 2. Configuração do Back-End

#### Estrutura:

```
furia-backend/
├── index.js             # Servidor Express principal
├── .env                 # Variável de ambiente com a chave da OpenAI
├── package.json         # Dependências do Node.js
```

#### Dependências:

```bash
npm install express cors dotenv openai
```

#### Arquivos:
Criei os arquivos Index.js e package.json
```

#### Código Principal (index.js):

```js
import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import OpenAI from 'openai';

dotenv.config();
const app = express();
app.use(cors());
app.use(express.json());

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/api/chat', async (req, res) => {
  const { prompt } = req.body;
  if (!prompt) return res.status(400).json({ error: 'Prompt é obrigatório!' });

  try {
    const chatCompletion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'Você é um assistente que só responde perguntas sobre a FURIA e-sports.' },
        { role: 'user', content: prompt },
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    res.json({ message: chatCompletion.choices[0].message.content });
  } catch (error) {
    console.error('Erro ao chamar OpenAI:', error.message);
    res.status(500).json({ error: 'Erro interno ao processar sua solicitação.' });
  }
});

const PORT = process.env.PORT || 3001;
app.listen(PORT, () => {
  console.log(`Servidor rodando na porta ${PORT}`);
});
```
#### Código (packages.json)
{
    "name": "furia-backend",
    "version": "1.0.0",
    "main": "index.js",
    "type": "module",
    "scripts": {
      "start": "node index.js"
    },
    "dependencies": {
      "cors": "^2.8.5",
      "dotenv": "^16.0.3",
      "express": "^4.18.2",
      "openai": "^4.0.0"
    }
  }
---

### 3. Deploy do Back-End no Render

1. Subi o projeto em um repositório GitHub (https://github.com/LedroPucas/furiabackend).
2. E ultilizando o Repositório, subi no Render [https://render.com](https://render.com) e criei um novo **Web Service**.
3. Adicionei a variável de ambiente `OPENAI_API_KEY`
4. Após o deploy, copiei a URL fornecida (ex: `https://furia-backend.onrender.com`) para a aplicação no Front

---

### 4. Front-End

#### Arquivo `App.js`:


``` REACT
1. Ultilizei do React, para a criação da tela, ultilizando de melhores práticas com UI/UX, para melhor experiencia do usuario,
fazendo a criação de todos os componentes, e as requisições e respostas do chat gpt;
2. No mesmo, adicionei as variaveis de comportamento do GPT, para que o usuario apenas faça perguntas sobre a furia,
e caso faça perguntas de outro tipo, ele sera alertado.

```js
1. coloquei na variavel result o Link hosteado do Render, onde é possivel encontrar minha Key do Gpt:
const result = await axios.post("https://furia-backend.onrender.com/api/chat", { prompt });
---

```Hospedagem
Logo após tudo concluido, subi o Front-End no Github (https://github.com/LedroPucas/TesteFuria1), e ultilizando o repositório, Hospedei no Vercel (https://teste-furia1.vercel.app/)
onde ficará disponivel para visualização

## Executando Localmente

### Back-end:
```bash
# Na pasta do back-end
npm install
npm start
```

### Front-end:
```bash
# Na pasta do front-end
npm install
npm start
```

## Estrutura Completa do Projeto

```

#Back-End
furiabackend/
│   ├── index.js
│   ├── .env
│   └── package.json


#Front-End
TESTEFURIA/
│   ├── src/
│   │   ├── App.js
│   │   ├── App.css
│   │   ├── assets/
│   │   └── index.js
│   ├── public/
│   ├── package.json
│   └── .env (não necessário após integração com backend)
```

---

## Conclusão

Este projeto demonstra a integração entre **React (front-end)** e **Node.js com Express (back-end)**, utilizando a **API da OpenAI**
para criar uma experiência personalizada de chatbot para a Fúria, tendo como base, outros sites mantendo ao máximo a identidade da Furia.
Com segurança, escalabilidade e uma interface amigável, o **FURIA Chat** agradeço imensamente a ateção, e espero que tenham gostado!.
